{
 "cells": [
  {
   "cell_type": "code",
   "id": "519b9895787d7bbb",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-11T00:57:33.388369Z",
     "start_time": "2024-07-11T00:57:33.371823Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from src import train, predict\n",
    "from src.utils import plot_fit_figures\n",
    "import traceback\n",
    "from src.models import LSTM\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import itertools\n",
    "from src.utils import eval_func\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T00:57:33.403593Z",
     "start_time": "2024-07-11T00:57:33.389369Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 超参数的可能值\n",
    "best_params = {\n",
    "    'hidden_size': 56,\n",
    "    'num_layers': 2,\n",
    "    'batch_size': 64,\n",
    "    'seq_len': 64,\n",
    "}\n",
    "\n",
    "hidden_size_options = [64]\n",
    "num_layers_options = [2]\n",
    "batch_size_options = [64]\n",
    "seq_len_options = [64]\n",
    "# 所有超参数组合\n",
    "param_grid = list(itertools.product(hidden_size_options, num_layers_options, batch_size_options, seq_len_options))"
   ],
   "id": "fc70ff7351908720",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T00:57:33.419593Z",
     "start_time": "2024-07-11T00:57:33.405591Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "208446b58d0448ff",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T00:57:34.817462Z",
     "start_time": "2024-07-11T00:57:33.421591Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run(best_config: dict, fund_code: str):\n",
    "    model = LSTM(input_size=7,\n",
    "                 output_size=7,\n",
    "                 hidden_size=best_config['hidden_size'],\n",
    "                 num_layers=best_config['num_layers'],\n",
    "                 )\n",
    "    config = {\n",
    "        'model': model,\n",
    "        'fund_code': fund_code,\n",
    "        'data_set_length': 1000,\n",
    "        'batch_size': best_config['batch_size'],\n",
    "        'num_epochs': 60,\n",
    "        'seq_len': best_config['seq_len'],\n",
    "    }\n",
    "    train(**config)\n",
    "    config.pop('num_epochs')\n",
    "    config.pop('data_set_length')\n",
    "    predictions, groundtruths = predict(**config)\n",
    "    plot_fit_figures(fund_code=fund_code, predictions=predictions, groundtruths=groundtruths)\n",
    "    mse, mae, rmse, smape = eval_func(predictions, groundtruths)\n",
    "    print(f'mse: {mse}, mae: {mae}, rmse: {rmse}, smape: {smape}')\n",
    "    return predictions, groundtruths\n"
   ],
   "id": "83fd231bc15bd7ae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------数据集加载中-------\n",
      "Dataset type: train, data length: 726\n",
      "Dataset type: valid, data length: 231\n",
      "--------加载完成---------\n",
      "----开始在cuda上训练------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练中: 217003: 100%|██████████| 60/60 [00:01<00:00, 49.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------训练完成---------\n",
      "-----loss曲线绘制完成-----\n",
      "-------模型保存完成-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 31,
   "source": "run(best_params, fund_code='000079')",
   "id": "7931c9a8564a62bf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T00:57:35.005157Z",
     "start_time": "2024-07-11T00:57:34.819354Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config.pop('num_epochs')\n",
    "config.pop('data_set_length')\n",
    "predictions, groundtruths = predict(**config)"
   ],
   "id": "3951322ab2a16a05",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Workplace\\PythonProjects\\IntelliFund\\src\\predict.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(f'checkpoints/{fund_code}.pt')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset type: test, data length: 1621\n",
      "---------开始预测---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:00<00:00, 466.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------预测完成---------\n",
      "---------评估完成---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T00:57:35.596948Z",
     "start_time": "2024-07-11T00:57:35.006142Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "plot_fit_figures(fund_code=fund_code, predictions=predictions, groundtruths=groundtruths)\n"
   ],
   "id": "c67293d844783088",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T00:57:35.611841Z",
     "start_time": "2024-07-11T00:57:35.597845Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def grid_search(param_grid, fund_code):\n",
    "    with open('grid_search_results.csv', 'w', encoding=\"utf-8\") as f:\n",
    "        f.write('hidden_size,num_layers,batch_size,seq_len,mse,mae,rmse,smape\\n')\n",
    "        for param in tqdm(param_grid):\n",
    "            hidden_size, num_layers, batch_size, seq_len = param\n",
    "            model = LSTM(input_size=7,\n",
    "                         output_size=7,\n",
    "                         hidden_size=hidden_size,\n",
    "                         num_layers=num_layers,\n",
    "                         )\n",
    "            config = {\n",
    "                'model': model,\n",
    "                'fund_code': fund_code,\n",
    "                'data_set_length': 1000,\n",
    "                'batch_size': batch_size,\n",
    "                'num_epochs': 60,\n",
    "                'seq_len': seq_len,\n",
    "            }\n",
    "            try:\n",
    "                train(**config)\n",
    "                config.pop('num_epochs')\n",
    "                config.pop('data_set_length')\n",
    "                predictions, groundtruths = predict(**config)\n",
    "                plot_fit_figures(fund_code=fund_code, predictions=predictions, groundtruths=groundtruths)\n",
    "                mse, mae, rmse, smape = eval_func(predictions, groundtruths)\n",
    "                f.write(f'{hidden_size},{num_layers},{batch_size},{seq_len},{mse},{mae},{rmse},{smape}\\n')\n",
    "\n",
    "            except Exception as e:\n",
    "                print(param)\n",
    "                print(traceback.format_exc())\n",
    "                continue\n"
   ],
   "id": "c76a006ffaa13d87",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T00:57:54.852342Z",
     "start_time": "2024-07-11T00:57:35.612841Z"
    }
   },
   "cell_type": "code",
   "source": "grid_search(param_grid, fund_code)",
   "id": "initial_id",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------数据集加载中-------\n",
      "Dataset type: train, data length: 707\n",
      "Dataset type: valid, data length: 177\n",
      "--------加载完成---------\n",
      "----开始在cuda上训练------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "训练中: 217003:   0%|          | 0/60 [00:00<?, ?it/s]\u001B[A\n",
      "训练中: 217003:   5%|▌         | 3/60 [00:00<00:02, 27.73it/s]\u001B[A\n",
      "训练中: 217003:  10%|█         | 6/60 [00:00<00:01, 28.16it/s]\u001B[A\n",
      "训练中: 217003:  15%|█▌        | 9/60 [00:00<00:01, 28.22it/s]\u001B[A\n",
      "训练中: 217003:  20%|██        | 12/60 [00:00<00:01, 28.49it/s]\u001B[A\n",
      "训练中: 217003:  25%|██▌       | 15/60 [00:00<00:01, 27.82it/s]\u001B[A\n",
      "训练中: 217003:  30%|███       | 18/60 [00:00<00:01, 28.34it/s]\u001B[A\n",
      "训练中: 217003:  35%|███▌      | 21/60 [00:00<00:01, 28.40it/s]\u001B[A\n",
      "训练中: 217003:  40%|████      | 24/60 [00:00<00:01, 28.35it/s]\u001B[A\n",
      "训练中: 217003:  45%|████▌     | 27/60 [00:00<00:01, 27.52it/s]\u001B[A\n",
      "训练中: 217003:  50%|█████     | 30/60 [00:01<00:01, 26.96it/s]\u001B[A\n",
      "训练中: 217003:  55%|█████▌    | 33/60 [00:01<00:01, 26.87it/s]\u001B[A\n",
      "训练中: 217003:  60%|██████    | 36/60 [00:01<00:00, 26.19it/s]\u001B[A\n",
      "训练中: 217003:  65%|██████▌   | 39/60 [00:01<00:00, 25.69it/s]\u001B[A\n",
      "训练中: 217003:  70%|███████   | 42/60 [00:01<00:00, 25.35it/s]\u001B[A\n",
      "训练中: 217003:  75%|███████▌  | 45/60 [00:01<00:00, 25.40it/s]\u001B[A\n",
      "训练中: 217003:  80%|████████  | 48/60 [00:01<00:00, 25.44it/s]\u001B[A\n",
      "训练中: 217003:  85%|████████▌ | 51/60 [00:01<00:00, 25.76it/s]\u001B[A\n",
      "训练中: 217003:  90%|█████████ | 54/60 [00:02<00:00, 25.97it/s]\u001B[A\n",
      "训练中: 217003:  95%|█████████▌| 57/60 [00:02<00:00, 26.27it/s]\u001B[A\n",
      "训练中: 217003: 100%|██████████| 60/60 [00:02<00:00, 26.72it/s]\u001B[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------训练完成---------\n",
      "-----loss曲线绘制完成-----\n",
      "-------模型保存完成-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Workplace\\PythonProjects\\IntelliFund\\src\\predict.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(f'checkpoints/{fund_code}.pt')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset type: test, data length: 1567\n",
      "---------开始预测---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 23/23 [00:00<00:00, 560.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------预测完成---------\n",
      "---------评估完成---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 17%|█▋        | 1/6 [00:03<00:16,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------数据集加载中-------\n",
      "Dataset type: train, data length: 712\n",
      "Dataset type: valid, data length: 190\n",
      "--------加载完成---------\n",
      "----开始在cuda上训练------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "训练中: 217003:   0%|          | 0/60 [00:00<?, ?it/s]\u001B[A\n",
      "训练中: 217003:   3%|▎         | 2/60 [00:00<00:03, 18.31it/s]\u001B[A\n",
      "训练中: 217003:   7%|▋         | 4/60 [00:00<00:03, 18.18it/s]\u001B[A\n",
      "训练中: 217003:  12%|█▏        | 7/60 [00:00<00:02, 20.01it/s]\u001B[A\n",
      "训练中: 217003:  17%|█▋        | 10/60 [00:00<00:02, 21.21it/s]\u001B[A\n",
      "训练中: 217003:  22%|██▏       | 13/60 [00:00<00:01, 23.85it/s]\u001B[A\n",
      "训练中: 217003:  28%|██▊       | 17/60 [00:00<00:01, 26.19it/s]\u001B[A\n",
      "训练中: 217003:  33%|███▎      | 20/60 [00:00<00:01, 26.65it/s]\u001B[A\n",
      "训练中: 217003:  38%|███▊      | 23/60 [00:00<00:01, 27.29it/s]\u001B[A\n",
      "训练中: 217003:  45%|████▌     | 27/60 [00:01<00:01, 28.53it/s]\u001B[A\n",
      "训练中: 217003:  50%|█████     | 30/60 [00:01<00:01, 28.62it/s]\u001B[A\n",
      "训练中: 217003:  57%|█████▋    | 34/60 [00:01<00:00, 29.09it/s]\u001B[A\n",
      "训练中: 217003:  62%|██████▏   | 37/60 [00:01<00:00, 28.68it/s]\u001B[A\n",
      "训练中: 217003:  67%|██████▋   | 40/60 [00:01<00:00, 28.80it/s]\u001B[A\n",
      "训练中: 217003:  72%|███████▏  | 43/60 [00:01<00:00, 29.13it/s]\u001B[A\n",
      "训练中: 217003:  77%|███████▋  | 46/60 [00:01<00:00, 29.29it/s]\u001B[A\n",
      "训练中: 217003:  82%|████████▏ | 49/60 [00:01<00:00, 28.64it/s]\u001B[A\n",
      "训练中: 217003:  87%|████████▋ | 52/60 [00:01<00:00, 28.62it/s]\u001B[A\n",
      "训练中: 217003:  92%|█████████▏| 55/60 [00:02<00:00, 28.30it/s]\u001B[A\n",
      "训练中: 217003: 100%|██████████| 60/60 [00:02<00:00, 26.97it/s]\u001B[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------训练完成---------\n",
      "-----loss曲线绘制完成-----\n",
      "-------模型保存完成-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Workplace\\PythonProjects\\IntelliFund\\src\\predict.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(f'checkpoints/{fund_code}.pt')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset type: test, data length: 1581\n",
      "---------开始预测---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 23/23 [00:00<00:00, 676.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------预测完成---------\n",
      "---------评估完成---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 33%|███▎      | 2/6 [00:06<00:13,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------数据集加载中-------\n",
      "Dataset type: train, data length: 717\n",
      "Dataset type: valid, data length: 204\n",
      "--------加载完成---------\n",
      "----开始在cuda上训练------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "训练中: 217003:   0%|          | 0/60 [00:00<?, ?it/s]\u001B[A\n",
      "训练中: 217003:   5%|▌         | 3/60 [00:00<00:02, 24.83it/s]\u001B[A\n",
      "训练中: 217003:  10%|█         | 6/60 [00:00<00:02, 23.85it/s]\u001B[A\n",
      "训练中: 217003:  15%|█▌        | 9/60 [00:00<00:02, 25.08it/s]\u001B[A\n",
      "训练中: 217003:  20%|██        | 12/60 [00:00<00:01, 25.29it/s]\u001B[A\n",
      "训练中: 217003:  25%|██▌       | 15/60 [00:00<00:01, 25.89it/s]\u001B[A\n",
      "训练中: 217003:  30%|███       | 18/60 [00:00<00:01, 26.90it/s]\u001B[A\n",
      "训练中: 217003:  35%|███▌      | 21/60 [00:00<00:01, 27.33it/s]\u001B[A\n",
      "训练中: 217003:  40%|████      | 24/60 [00:00<00:01, 27.67it/s]\u001B[A\n",
      "训练中: 217003:  45%|████▌     | 27/60 [00:01<00:01, 28.27it/s]\u001B[A\n",
      "训练中: 217003:  50%|█████     | 30/60 [00:01<00:01, 28.43it/s]\u001B[A\n",
      "训练中: 217003:  55%|█████▌    | 33/60 [00:01<00:00, 27.99it/s]\u001B[A\n",
      "训练中: 217003:  60%|██████    | 36/60 [00:01<00:00, 27.68it/s]\u001B[A\n",
      "训练中: 217003:  65%|██████▌   | 39/60 [00:01<00:00, 28.11it/s]\u001B[A\n",
      "训练中: 217003:  70%|███████   | 42/60 [00:01<00:00, 26.97it/s]\u001B[A\n",
      "训练中: 217003:  75%|███████▌  | 45/60 [00:01<00:00, 26.20it/s]\u001B[A\n",
      "训练中: 217003:  80%|████████  | 48/60 [00:01<00:00, 26.18it/s]\u001B[A\n",
      "训练中: 217003:  85%|████████▌ | 51/60 [00:01<00:00, 26.57it/s]\u001B[A\n",
      "训练中: 217003:  90%|█████████ | 54/60 [00:02<00:00, 27.03it/s]\u001B[A\n",
      "训练中: 217003:  95%|█████████▌| 57/60 [00:02<00:00, 26.38it/s]\u001B[A\n",
      "训练中: 217003: 100%|██████████| 60/60 [00:02<00:00, 26.62it/s]\u001B[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------训练完成---------\n",
      "-----loss曲线绘制完成-----\n",
      "-------模型保存完成-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Workplace\\PythonProjects\\IntelliFund\\src\\predict.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(f'checkpoints/{fund_code}.pt')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset type: test, data length: 1594\n",
      "---------开始预测---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 23/23 [00:00<00:00, 689.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------预测完成---------\n",
      "---------评估完成---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 3/6 [00:09<00:09,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------数据集加载中-------\n",
      "Dataset type: train, data length: 726\n",
      "Dataset type: valid, data length: 231\n",
      "--------加载完成---------\n",
      "----开始在cuda上训练------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "训练中: 217003:   0%|          | 0/60 [00:00<?, ?it/s]\u001B[A\n",
      "训练中: 217003:   5%|▌         | 3/60 [00:00<00:02, 23.58it/s]\u001B[A\n",
      "训练中: 217003:  10%|█         | 6/60 [00:00<00:02, 22.22it/s]\u001B[A\n",
      "训练中: 217003:  15%|█▌        | 9/60 [00:00<00:02, 23.45it/s]\u001B[A\n",
      "训练中: 217003:  20%|██        | 12/60 [00:00<00:01, 25.49it/s]\u001B[A\n",
      "训练中: 217003:  25%|██▌       | 15/60 [00:00<00:01, 26.69it/s]\u001B[A\n",
      "训练中: 217003:  30%|███       | 18/60 [00:00<00:01, 27.71it/s]\u001B[A\n",
      "训练中: 217003:  37%|███▋      | 22/60 [00:00<00:01, 29.17it/s]\u001B[A\n",
      "训练中: 217003:  42%|████▏     | 25/60 [00:00<00:01, 28.88it/s]\u001B[A\n",
      "训练中: 217003:  48%|████▊     | 29/60 [00:01<00:01, 29.45it/s]\u001B[A\n",
      "训练中: 217003:  55%|█████▌    | 33/60 [00:01<00:00, 29.85it/s]\u001B[A\n",
      "训练中: 217003:  62%|██████▏   | 37/60 [00:01<00:00, 30.52it/s]\u001B[A\n",
      "训练中: 217003:  68%|██████▊   | 41/60 [00:01<00:00, 30.50it/s]\u001B[A\n",
      "训练中: 217003:  75%|███████▌  | 45/60 [00:01<00:00, 30.37it/s]\u001B[A\n",
      "训练中: 217003:  82%|████████▏ | 49/60 [00:01<00:00, 30.35it/s]\u001B[A\n",
      "训练中: 217003:  88%|████████▊ | 53/60 [00:01<00:00, 30.13it/s]\u001B[A\n",
      "训练中: 217003: 100%|██████████| 60/60 [00:02<00:00, 28.97it/s]\u001B[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------训练完成---------\n",
      "-----loss曲线绘制完成-----\n",
      "-------模型保存完成-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Workplace\\PythonProjects\\IntelliFund\\src\\predict.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(f'checkpoints/{fund_code}.pt')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset type: test, data length: 1621\n",
      "---------开始预测---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 23/23 [00:00<00:00, 636.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------预测完成---------\n",
      "---------评估完成---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 67%|██████▋   | 4/6 [00:12<00:06,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------数据集加载中-------\n",
      "Dataset type: train, data length: 736\n",
      "Dataset type: valid, data length: 258\n",
      "--------加载完成---------\n",
      "----开始在cuda上训练------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "训练中: 217003:   0%|          | 0/60 [00:00<?, ?it/s]\u001B[A\n",
      "训练中: 217003:   5%|▌         | 3/60 [00:00<00:02, 28.30it/s]\u001B[A\n",
      "训练中: 217003:  10%|█         | 6/60 [00:00<00:01, 27.78it/s]\u001B[A\n",
      "训练中: 217003:  15%|█▌        | 9/60 [00:00<00:01, 27.90it/s]\u001B[A\n",
      "训练中: 217003:  20%|██        | 12/60 [00:00<00:01, 28.68it/s]\u001B[A\n",
      "训练中: 217003:  25%|██▌       | 15/60 [00:00<00:01, 28.74it/s]\u001B[A\n",
      "训练中: 217003:  30%|███       | 18/60 [00:00<00:01, 28.87it/s]\u001B[A\n",
      "训练中: 217003:  35%|███▌      | 21/60 [00:00<00:01, 29.14it/s]\u001B[A\n",
      "训练中: 217003:  42%|████▏     | 25/60 [00:00<00:01, 29.70it/s]\u001B[A\n",
      "训练中: 217003:  47%|████▋     | 28/60 [00:00<00:01, 29.69it/s]\u001B[A\n",
      "训练中: 217003:  52%|█████▏    | 31/60 [00:01<00:00, 29.49it/s]\u001B[A\n",
      "训练中: 217003:  57%|█████▋    | 34/60 [00:01<00:00, 29.40it/s]\u001B[A\n",
      "训练中: 217003:  63%|██████▎   | 38/60 [00:01<00:00, 30.11it/s]\u001B[A\n",
      "训练中: 217003:  70%|███████   | 42/60 [00:01<00:00, 30.40it/s]\u001B[A\n",
      "训练中: 217003:  77%|███████▋  | 46/60 [00:01<00:00, 29.64it/s]\u001B[A\n",
      "训练中: 217003:  83%|████████▎ | 50/60 [00:01<00:00, 30.19it/s]\u001B[A\n",
      "训练中: 217003:  90%|█████████ | 54/60 [00:01<00:00, 30.26it/s]\u001B[A\n",
      "训练中: 217003: 100%|██████████| 60/60 [00:02<00:00, 29.50it/s]\u001B[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------训练完成---------\n",
      "-----loss曲线绘制完成-----\n",
      "-------模型保存完成-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Workplace\\PythonProjects\\IntelliFund\\src\\predict.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(f'checkpoints/{fund_code}.pt')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset type: test, data length: 1649\n",
      "---------开始预测---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 23/23 [00:00<00:00, 603.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------预测完成---------\n",
      "---------评估完成---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 83%|████████▎ | 5/6 [00:15<00:03,  3.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------数据集加载中-------\n",
      "Dataset type: train, data length: 774\n",
      "Dataset type: valid, data length: 367\n",
      "--------加载完成---------\n",
      "----开始在cuda上训练------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "训练中: 217003:   0%|          | 0/60 [00:00<?, ?it/s]\u001B[A\n",
      "训练中: 217003:   5%|▌         | 3/60 [00:00<00:02, 28.27it/s]\u001B[A\n",
      "训练中: 217003:  10%|█         | 6/60 [00:00<00:01, 28.45it/s]\u001B[A\n",
      "训练中: 217003:  17%|█▋        | 10/60 [00:00<00:01, 29.63it/s]\u001B[A\n",
      "训练中: 217003:  22%|██▏       | 13/60 [00:00<00:01, 29.55it/s]\u001B[A\n",
      "训练中: 217003:  27%|██▋       | 16/60 [00:00<00:01, 29.31it/s]\u001B[A\n",
      "训练中: 217003:  32%|███▏      | 19/60 [00:00<00:01, 29.34it/s]\u001B[A\n",
      "训练中: 217003:  37%|███▋      | 22/60 [00:00<00:01, 29.42it/s]\u001B[A\n",
      "训练中: 217003:  42%|████▏     | 25/60 [00:00<00:01, 28.71it/s]\u001B[A\n",
      "训练中: 217003:  47%|████▋     | 28/60 [00:00<00:01, 27.15it/s]\u001B[A\n",
      "训练中: 217003:  52%|█████▏    | 31/60 [00:01<00:01, 26.52it/s]\u001B[A\n",
      "训练中: 217003:  57%|█████▋    | 34/60 [00:01<00:00, 26.36it/s]\u001B[A\n",
      "训练中: 217003:  62%|██████▏   | 37/60 [00:01<00:00, 25.96it/s]\u001B[A\n",
      "训练中: 217003:  67%|██████▋   | 40/60 [00:01<00:00, 26.55it/s]\u001B[A\n",
      "训练中: 217003:  72%|███████▏  | 43/60 [00:01<00:00, 26.62it/s]\u001B[A\n",
      "训练中: 217003:  77%|███████▋  | 46/60 [00:01<00:00, 26.33it/s]\u001B[A\n",
      "训练中: 217003:  82%|████████▏ | 49/60 [00:01<00:00, 25.85it/s]\u001B[A\n",
      "训练中: 217003:  87%|████████▋ | 52/60 [00:01<00:00, 25.33it/s]\u001B[A\n",
      "训练中: 217003:  92%|█████████▏| 55/60 [00:02<00:00, 25.49it/s]\u001B[A\n",
      "训练中: 217003: 100%|██████████| 60/60 [00:02<00:00, 26.89it/s]\u001B[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------训练完成---------\n",
      "-----loss曲线绘制完成-----\n",
      "-------模型保存完成-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Workplace\\PythonProjects\\IntelliFund\\src\\predict.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(f'checkpoints/{fund_code}.pt')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset type: test, data length: 1757\n",
      "---------开始预测---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 23/23 [00:00<00:00, 430.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------预测完成---------\n",
      "---------评估完成---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 6/6 [00:19<00:00,  3.20s/it]\n"
     ]
    }
   ],
   "execution_count": 35
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
